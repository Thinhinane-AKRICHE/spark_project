{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9ff44cc",
   "metadata": {},
   "source": [
    "# Les imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b702cd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col,lit,concat\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b142ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYSPARK_PYTHON\"] = sys.executable\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e718230",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession.builder\n",
    "         .master(\"local[*]\")\n",
    "         .config(\"spark.pyspark.python\", sys.executable)\n",
    "         .config(\"spark.pyspark.driver.python\", sys.executable)\n",
    "         .config(\"spark.python.worker.reuse\", \"true\")\n",
    "         .config(\"spark.python.worker.timeout\", \"300\")\n",
    "         .getOrCreate())\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19cea89",
   "metadata": {},
   "source": [
    "# Les chemins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0c5a3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = r\"C:\\spark_project\\Dataset\"\n",
    "csv_file = r\"C:\\spark_project\\Dataset\\UrbanSound8K.csv\"\n",
    "out_base = r\"C:\\spark_project\\Dataset_Sorted_by_class\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48f0ccc",
   "metadata": {},
   "source": [
    "# Lecture de csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85a96867",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (spark.read\n",
    "    .option(\"header\", True)\n",
    "    .option(\"inferSchema\", True)\n",
    "    .csv(csv_file)\n",
    "    .select(\n",
    "        col(\"slice_file_name\").alias(\"file\"), #on renomme la colonne par file\n",
    "        col(\"fold\").cast(\"int\"),\n",
    "        col(\"class\").alias(\"class_name\")\n",
    "    )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c9fcfe",
   "metadata": {},
   "source": [
    "# construction des chemins source/destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfcb3fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paths =(\n",
    "    df.withColumn(\"src\", concat(lit(dataset), lit(\"/fold\"), col(\"fold\"), lit(\"/\"), col(\"file\"))) # equivalent en pandas : df[\"src\"] = (dataset+\"/fold\"+ df[\"fold\"].astype(str)+\"/\"+df[\"file\"]) // on construit le chemain de source du fichier\n",
    "    .withColumn(\"dst_class_dir\", concat(lit(out_base), lit(\"/\"), col(\"class_name\"))) # on construit le dossier destination de la classe \n",
    "    .withColumn(\"dst_file\", concat(col(\"dst_class_dir\"), lit(\"/\"), col(\"file\"))) # on construit le chemain destination de fichier \n",
    "    .select(\"src\", \"dst_class_dir\", \"dst_file\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e633dd5c",
   "metadata": {},
   "source": [
    "# conversion en csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ba919b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paths.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"header\", True) \\\n",
    "    .csv(r\"C:\\spark_project\\Dataset\\df_paths_csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d0f566",
   "metadata": {},
   "source": [
    "# Copier les audios dans les nvs dossiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59ef6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_partition(rows):\n",
    "    \"\"\"Traite une partition de fichiers\"\"\"\n",
    "    import os\n",
    "    import shutil\n",
    "    \n",
    "    stats = {\"copied\": 0, \"skipped\": 0, \"errors\": 0}\n",
    "    \n",
    "    for row in rows:\n",
    "        try:\n",
    "            src = row[\"src\"]\n",
    "            dst_class_dir = row[\"dst_class_dir\"]\n",
    "            dst_file = row[\"dst_file\"]\n",
    "            \n",
    "            # Créer le dossier de destination\n",
    "            os.makedirs(dst_class_dir, exist_ok=True)\n",
    "            \n",
    "            # copier\n",
    "            if not os.path.exists(src):\n",
    "                stats[\"errors\"] += 1\n",
    "                continue\n",
    "                \n",
    "            if os.path.exists(dst_file):\n",
    "                stats[\"skipped\"] += 1\n",
    "                continue\n",
    "            \n",
    "            shutil.copy2(src, dst_file)\n",
    "            stats[\"copied\"] += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            stats[\"errors\"] += 1\n",
    "            print(f\"Erreur sur {src}: {e}\")\n",
    "    \n",
    "    return [stats]\n",
    "\n",
    "df_paths_optimized = df_paths.repartition(2)\n",
    "\n",
    "# Exécuter le traitement\n",
    "results = df_paths_optimized.rdd.mapPartitions(process_partition).collect()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
