{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cff1ff50",
   "metadata": {},
   "source": [
    "# Lecture de dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b83923f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col\n",
    "import os,sys\n",
    "import io\n",
    "import librosa\n",
    "from pyspark.sql.types import BinaryType, StructType, StructField, IntegerType, FloatType, StringType, BinaryType, FloatType\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b5c4db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYSPARK_PYTHON\"] = sys.executable\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40eccb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession.builder\n",
    "         .master(\"local[*]\")\n",
    "         .config(\"spark.pyspark.python\", sys.executable)\n",
    "         .config(\"spark.pyspark.driver.python\", sys.executable)\n",
    "         .config(\"spark.python.worker.reuse\", \"true\")\n",
    "         .config(\"spark.python.worker.timeout\", \"300\")\n",
    "         .getOrCreate())\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51ad235",
   "metadata": {},
   "source": [
    "# Le shéma des métadonnées audio qu'on va récupérer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75fb4f3",
   "metadata": {},
   "source": [
    "# Version 01 : Traitement depuis le contenu binaire(Spark UDF) : Très lent voir inexécutable (sur ma machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ef844c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_metadata_schema = StructType([\n",
    "    StructField(\"audio_data\", BinaryType(), True), #on parle sur les valeurs y de nos signaux \n",
    "    StructField(\"sample_rate\", IntegerType(), True), #les fréquences d'échantillonages\n",
    "    StructField(\"duration\", FloatType(), True),  #les valeurs x les durées \n",
    "    StructField(\"num_samples\", IntegerType(), True)  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51de320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_audio(file_content):\n",
    "    try:\n",
    "        #On charge l'audio\n",
    "        audio_bytes = io.BytesIO(file_content) #permet de transformer des bytes en faux fichiers en mémoire (objets mémoire virtuel RAM)\n",
    "        y, sr = librosa.load(audio_bytes, sr=None, mono=False) #on récupère les valeurs y, on change pas la fr d'échantillonage et on force pas la transformation vers mono\n",
    "\n",
    "        #Convertir en mono si stréo\n",
    "        if y.ndim > 1:\n",
    "            y = librosa.to_mono(y)\n",
    "\n",
    "        #réchantillionage à 22050 hz => fr stadard\n",
    "        target_sr = 22050\n",
    "        if sr != target_sr:\n",
    "            y = librosa.resample(y, orig_sr=sr, target_sr=target_sr)\n",
    "            sr = target_sr\n",
    "\n",
    "        # normalisation des apmlitudes y \n",
    "        y = librosa.util.normalize(y)\n",
    "\n",
    "        # supression des silences de début et de fin (20 db plus faible que le son originale)\n",
    "        y_trimmed, _ = librosa.effects.trim(y, top_db=20)\n",
    "\n",
    "\n",
    "        # filtarge du bruit seuil = 0.01 => une fois après la normalisation,\n",
    "        # les valeurs de y sont entre 0 et 1 dpnc max = 1 et 0.01 reprèsente 1% de max => trop faible pour etre un vrai son\n",
    "        threshold = 0.01\n",
    "        y_trimmed[np.abs(y_trimmed) < threshold] = 0\n",
    "\n",
    "        # sauvegarder en bytes \n",
    "        # on transfrome y_trimmed qui est np.array en un wav encodé en RAM avec un header et des les données audios : en les codes en bytes \n",
    "        buffer = io.BytesIO()\n",
    "        sf.write(buffer, y_trimmed, sr, format='WAV') #recréer un wav propres ave le signal audio : numpy array : y_trimmed et la fréquence sr dans le buffer mémoire\n",
    "        audio_bytes_processed = buffer.getvalue() #récupère les bytes finaux \n",
    "\n",
    "        # Métadonnées\n",
    "        duration = len(y_trimmed) / sr #le nbr d'échantillons total / le nbr d'échantillions par seconde = durée \n",
    "        num_samples = len(y_trimmed) #le nbr total des échantillions du signal après traitement (nbr d'element du tableau y-trimmed)\n",
    "       \n",
    "\n",
    "        return (audio_bytes_processed, sr, duration, num_samples)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur de prétraitement: {str(e)}\")\n",
    "        return (None, None, None, None)\n",
    "\n",
    "# Créeration de l'UDF\n",
    "preprocess_udf = udf(preprocess_audio, audio_metadata_schema)\n",
    "\n",
    "# Charger les fichiers WAV\n",
    "df_audio = spark.read.format(\"binaryFile\").load(\"C:/spark_project/Dataset_Sorted_by_class/air_conditioner/*.wav\")\n",
    "print(\"df_audio récupéré\")\n",
    "\n",
    "# Appliquer le prétraitement\n",
    "df_preprocessed = df_audio.withColumn(\"preprocessed\", preprocess_udf(col(\"content\"))) \\\n",
    "    .select(\n",
    "        col(\"path\"),\n",
    "        col(\"preprocessed.audio_data\").alias(\"audio_preprocessed\"),\n",
    "        col(\"preprocessed.sample_rate\").alias(\"sample_rate\"),\n",
    "        col(\"preprocessed.duration\").alias(\"duration\"),\n",
    "        col(\"preprocessed.num_samples\").alias(\"num_samples\")\n",
    "    \n",
    "    .filter(col(\"audio_preprocessed\").isNotNull()) # filtrage des fichiers qui ont échoué\n",
    "    .cache()\n",
    "    )\n",
    "\n",
    "\n",
    "df_preprocessed.count()\n",
    "df_preprocessed.show(1, False)\n",
    "\n",
    "'''\n",
    "# Sauvegarder les résultats\n",
    "out_path = r\"C:\\spark_project\\Dataset_Sorted_by_class\\processed_audio\"\n",
    "df_preprocessed.write.mode(\"overwrite\").parquet(out_path)\n",
    "print(\"df_preprocessed\")\n",
    "\n",
    "print(f\"Nombre de fichiers prétraités: {df_preprocessed.count()}\")\n",
    "df_preprocessed.show(5, truncate=False)\n",
    "        \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b284f9",
   "metadata": {},
   "source": [
    "# Version 02: Traitement direct depuis le chemin du fichier (plus rapide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b63f6d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(r\"C:\\spark_project\\Dataset_Sorted_by_class\\air_conditioner\\*.wav\")\n",
    "rdd = spark.sparkContext.parallelize(files, numSlices=4) #On donne à spark une liste d'objets (chemains vers les fichiers) et il applique la fct python de praitrraitment à chacun en parallèle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd63ed48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_audio(file_path):\n",
    "    try:\n",
    "        #Charger l'audio depuis le chemin (pas de BytesIO)\n",
    "        y, sr = sf.read(file_path, dtype=\"float32\", always_2d=False)\n",
    "\n",
    "        #Convertir en mono si stréo\n",
    "        if y.ndim > 1:\n",
    "            y = librosa.to_mono(y)\n",
    "\n",
    "        #réchantillionage à 22050 hz => fr stadard\n",
    "        target_sr = 22050\n",
    "        if sr != target_sr:\n",
    "            y = librosa.resample(y, orig_sr=sr, target_sr=target_sr)\n",
    "            sr = target_sr\n",
    "\n",
    "        # normalisation des apmlitudes y \n",
    "        y = librosa.util.normalize(y)\n",
    "\n",
    "        # supression des silences de début et de fin (20 db plus faible que le son originale)\n",
    "        y_trimmed, _ = librosa.effects.trim(y, top_db=20)\n",
    "\n",
    "\n",
    "        # filtarge du bruit seuil = 0.01 => une fois après la normalisation,\n",
    "        # les valeurs de y sont entre 0 et 1 dpnc max = 1 et 0.01 reprèsente 1% de max => trop faible pour etre un vrai son\n",
    "        threshold = 0.01\n",
    "        y_trimmed[np.abs(y_trimmed) < threshold] = 0\n",
    "\n",
    "        # sauvegarder en bytes \n",
    "        # on transfrome y_trimmed qui est np.array en un wav encodé en RAM avec un header et des les données audios : en les codes en bytes \n",
    "        buffer = io.BytesIO()\n",
    "        sf.write(buffer, y_trimmed, sr, format='WAV') #recréer un wav propres ave le signal audio : numpy array : y_trimmed et la fréquence sr dans le buffer mémoire\n",
    "        audio_bytes_processed = buffer.getvalue() #récupère les bytes finaux \n",
    "\n",
    "        # Métadonnées\n",
    "        duration = float(len(y_trimmed) / sr) #le nbr d'échantillons total / le nbr d'échantillions par seconde = durée \n",
    "        num_samples = int(len(y_trimmed)) #le nbr total des échantillions du signal après traitement (nbr d'element du tableau y-trimmed)\n",
    "       \n",
    "\n",
    "        return (file_path, audio_bytes_processed, sr, duration, num_samples)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur de prétraitement: {str(e)}\")\n",
    "        return (file_path, None, None, None, None)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbdcfe4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+-----------+------------+-----------+\n",
      "|path                                                                      |audio_preprocessed                                                                                                                         |sample_rate|duration    |num_samples|\n",
      "+--------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+-----------+------------+-----------+\n",
      "|C:\\spark_project\\Dataset_Sorted_by_class\\air_conditioner\\13230-0-0-1.wav  |[52 49 46 46 26 00 00 00 57 41 56 45 66 6D 74 20 10 00 00 00 01 00 01 00 22 56 00 00 44 AC 00 00 02 00 10 00 64 61 74 61 02 00 00 00 00 80]|22050      |4.5351473E-5|1          |\n",
      "|C:\\spark_project\\Dataset_Sorted_by_class\\air_conditioner\\13230-0-0-3.wav  |[52 49 46 46 26 00 00 00 57 41 56 45 66 6D 74 20 10 00 00 00 01 00 01 00 22 56 00 00 44 AC 00 00 02 00 10 00 64 61 74 61 02 00 00 00 00 80]|22050      |4.5351473E-5|1          |\n",
      "|C:\\spark_project\\Dataset_Sorted_by_class\\air_conditioner\\13230-0-0-5.wav  |[52 49 46 46 26 00 00 00 57 41 56 45 66 6D 74 20 10 00 00 00 01 00 01 00 22 56 00 00 44 AC 00 00 02 00 10 00 64 61 74 61 02 00 00 00 00 80]|22050      |4.5351473E-5|1          |\n",
      "|C:\\spark_project\\Dataset_Sorted_by_class\\air_conditioner\\13230-0-0-6.wav  |[52 49 46 46 26 00 00 00 57 41 56 45 66 6D 74 20 10 00 00 00 01 00 01 00 22 56 00 00 44 AC 00 00 02 00 10 00 64 61 74 61 02 00 00 00 00 80]|22050      |4.5351473E-5|1          |\n",
      "|C:\\spark_project\\Dataset_Sorted_by_class\\air_conditioner\\167464-0-0-20.wav|[52 49 46 46 26 00 00 00 57 41 56 45 66 6D 74 20 10 00 00 00 01 00 01 00 22 56 00 00 44 AC 00 00 02 00 10 00 64 61 74 61 02 00 00 00 00 80]|22050      |4.5351473E-5|1          |\n",
      "|C:\\spark_project\\Dataset_Sorted_by_class\\air_conditioner\\167464-0-0-21.wav|[52 49 46 46 26 00 00 00 57 41 56 45 66 6D 74 20 10 00 00 00 01 00 01 00 22 56 00 00 44 AC 00 00 02 00 10 00 64 61 74 61 02 00 00 00 FF 7F]|22050      |4.5351473E-5|1          |\n",
      "|C:\\spark_project\\Dataset_Sorted_by_class\\air_conditioner\\167464-0-0-22.wav|[52 49 46 46 26 00 00 00 57 41 56 45 66 6D 74 20 10 00 00 00 01 00 01 00 22 56 00 00 44 AC 00 00 02 00 10 00 64 61 74 61 02 00 00 00 FF 7F]|22050      |4.5351473E-5|1          |\n",
      "|C:\\spark_project\\Dataset_Sorted_by_class\\air_conditioner\\167464-0-0-23.wav|[52 49 46 46 26 00 00 00 57 41 56 45 66 6D 74 20 10 00 00 00 01 00 01 00 22 56 00 00 44 AC 00 00 02 00 10 00 64 61 74 61 02 00 00 00 FF 7F]|22050      |4.5351473E-5|1          |\n",
      "|C:\\spark_project\\Dataset_Sorted_by_class\\air_conditioner\\167464-0-0-24.wav|[52 49 46 46 26 00 00 00 57 41 56 45 66 6D 74 20 10 00 00 00 01 00 01 00 22 56 00 00 44 AC 00 00 02 00 10 00 64 61 74 61 02 00 00 00 00 80]|22050      |4.5351473E-5|1          |\n",
      "|C:\\spark_project\\Dataset_Sorted_by_class\\air_conditioner\\170022-0-0-0.wav |[52 49 46 46 26 00 00 00 57 41 56 45 66 6D 74 20 10 00 00 00 01 00 01 00 22 56 00 00 44 AC 00 00 02 00 10 00 64 61 74 61 02 00 00 00 FF 7F]|22050      |4.5351473E-5|1          |\n",
      "+--------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------+-----------+------------+-----------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "\n",
    "schema = StructType([\n",
    "    StructField(\"path\", StringType(), True),\n",
    "    StructField(\"audio_preprocessed\", BinaryType(), True),\n",
    "    StructField(\"sample_rate\", IntegerType(), True),\n",
    "    StructField(\"duration\", FloatType(), True),\n",
    "    StructField(\"num_samples\", IntegerType(), True),\n",
    "])\n",
    "\n",
    "df_preprocessed = spark.createDataFrame(rdd.map(preprocess_audio), schema) \\\n",
    "    .filter(\"audio_preprocessed is not null\") \\\n",
    "    .cache()\n",
    "\n",
    "df_preprocessed.show(10, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4d69d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.getNumPartitions()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
